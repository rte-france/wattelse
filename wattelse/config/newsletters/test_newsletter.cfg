######## NEWSLETTER CONFIG ########
[newsletter]
id = test
title = Newsletter
top_n_topics = 5
top_n_docs = 3
output_format = html
output_directory = newsletter
summarizer_class = AbstractiveSummarizer
# “At 22:00 on every day-of-week from Monday through Friday.”
update_frequency = 0 23 * * 1-5

######## LEARNING STRATEGY ########
[learning_strategy]
# Choose among:
# - learn_from_scratch : uses all available data from feed to create the model
# - learn_from_last: uses only the last feed data to create the model
# - inference_only: do not retrain model; reuse existing bertopic model if available,
#   otherwise, fallback to learn_from_scratch for the first run
learning_strategy = inference_only
# model saving path (empty or None = do not save model)
bertopic_model_path = None

######## TOPIC MODEL CONFIG ########
[topic_model.embedding]
# embedding model to be used, authorized values:
# - dangvantuan/sentence-camembert-large
# - paraphrase-multilingual-MiniLM-L12-v2
# - sentence-transformers/all-mpnet-base-v2
model_name = sentence-transformers/all-mpnet-base-v2

[topic_model.topics]
# Topics
nr_topics = 0
top_n_words = 5

[topic_model.umap]
# UMAP
n_neighbors = 15
n_components = 5
min_dist = 0.0
metric = cosine

[topic_model.hdbscan]
# HDBScan
min_cluster_size = 10
min_samples = 10
metric = euclidian
cluster_selection_method = eom
prediction_data = True

[topic_model.count_vectorizer]
# Count Vectorizer
stop_words = french
ngram_range = (1,1)

[topic_model.c_tf_idf]
# c-TF-IDF
reduce_frequent_words = True

