[EVAL_CONFIG]
host = 0.0.0.0
port = 8888
port_controller = 21001
port_worker = 21002
cuda_visible_devices = 2,1

[EVALUATION_SEQUENCE]
# List of models to evaluate in sequence
models = meta-llama/Meta-Llama-3-8B-Instruct, prometheus-eval/prometheus-7b-v2.0
output_suffix = model_comparison

[MODEL_META-LLAMA-3-8B]
model_name = meta-llama/Meta-Llama-3-8B-Instruct
prompt_type = meta-llama-3-8b
regex_type = re_llama3
temperature = 0.0

[MODEL_PROMETHEUS]
model_name = prometheus-eval/prometheus-7b-v2.0
prompt_type = prometheus
regex_type = re_prometheus
temperature = 0.0