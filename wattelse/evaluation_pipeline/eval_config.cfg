[EVAL_CONFIG]
# TODO Don't need to pass these parameters here seperate the process
host = 0.0.0.0
port = 8888
port_controller = 21001
port_worker = 21002
cuda_visible_devices = 2,1
enabled_metrics = faithfulness,correctness,retrievability
# enabled_metrics = retrievability,correctness

# TODO  [MODEL_] can be simplified
[JURY_ROOM]
# List of models to evaluate in sequence
models = deepseek-ai/DeepSeek-R1-Distill-Llama-8B,AtlaAI/Selene-1-Mini-Llama-3.1-8B, meta-llama/Meta-Llama-3-8B-Instruct, prometheus-eval/prometheus-7b-v2.0
# ,meta-llama/Meta-Llama-3-8B-Instruct, prometheus-eval/prometheus-7b-v2.0
# models = wattelse-gpt4o-mini-sweden-dev, meta-llama/Meta-Llama-3-8B-Instruct, prometheus-eval/prometheus-7b-v2.0

[MODEL_FLOW_JUDGE-v0.1]
model_name = flowaicom/Flow-Judge-v0.1
prompt_type = meta-llama-3-8b
regex_type = re_llama3
temperature = 0.0

[MODEL_SELENE-1-MINI-LLAMA-3.1-8B]
model_name = AtlaAI/Selene-1-Mini-Llama-3.1-8B
prompt_type = meta-llama-3-8b
regex_type = re_llama3
temperature = 0.0

[MODEL_DEEPSEEK-R1-DISTILL-LLAMA-8B]
model_name = deepseek-ai/DeepSeek-R1-Distill-Llama-8B
prompt_type = meta-llama-3-8b
regex_type = re_llama3
temperature = 0.0

[MODEL_META-LLAMA-3-8B-INSTRUCT]
model_name = meta-llama/Meta-Llama-3-8B-Instruct
prompt_type = meta-llama-3-8b
regex_type = re_llama3
temperature = 0.0

[MODEL_PROMETHEUS-7B-V2.0]
model_name = prometheus-eval/prometheus-7b-v2.0
prompt_type = prometheus
regex_type = re_prometheus
temperature = 0.0

[MODEL_GPT4O-MINI-SWEDEN-DEV]
model_name = wattelse-gpt4o-mini-sweden-dev
deployment_type = azure
api_base = https://wattelse-openai-sweden.openai.azure.com
api_key = ${AZURE_API_KEY}
deployment_name = wattelse-gpt4o-mini-sweden-dev
prompt_type = default
regex_type = default
temperature = 0.0
