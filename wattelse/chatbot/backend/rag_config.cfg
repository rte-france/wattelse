[retriever]
# maximum number of extracts to return
top_n_extracts = 10
# retrieval method, choose among "mmr", "similarity", "similarity_score_threshold", "bm25", "ensemble"
retrieval_method = "similarity_score_threshold"
# similarity threshold (applies only for the method "similarity_score_threshold")
similarity_threshold = 0.3
# Generate alternative questions and retrieve documents based on those questions
# NB. Experimental feature... (generated questions may be out of scope)
multi_query_mode = False


[generator]
# type of LLM API: select the right environment variables (LEGACY_*, LOCAL_*, AZURE_WATTELSE_*)
openai_api_key = $LOCAL_OPENAI_API_KEY
openai_endpoint = $LOCAL_OPENAI_ENDPOINT
openai_default_model = $LOCAL_OPENAI_DEFAULT_MODEL_NAME

# response size: short or detailed
expected_answer_size = short
# use recent memory in interactions
remember_recent_messages = True
# generation temperature
temperature = 0.1
