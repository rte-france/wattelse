[retriever]
# reranker model, choose among
# - antoinelouis/crossencoder-camembert-base-mmarcoFR
# - dangvantuan/CrossEncoder-camembert-large
reranker_model_name = antoinelouis/crossencoder-camembert-base-mmarcoFR
# maximum number of extracts to return
top_n_extracts = 5
# retrieval mode, choose among
# "bm25", "dense", "hybrid", "hybrid+reranker"
retrieval_mode = hybrid
# similarity threshold
similarity_threshold = 0.3
# optimisation of storage, use of cache for embeddings
use_cache = True

[generator]
# type of LLM API: "Fastchat LLM" or "Ollama LLM" or "ChatGpt"
llm_api_name = Fastchat LLM
# response size: short or detailed
expected_answer_size = short
# use recent memory in interactions
remember_recent_messages = False
# custom prompt, if remember_recent_messages is True, shall be set to wattelse.llm.prompts.FR_USER_MULTITURN_RAG
custom_prompt = wattelse.api.prompts.FR_USER_BASE_RAG
# generation temperature
temperature = 0.1

[user]
# whether to launch app in user mode (no parameters in sidebar, fixed documents...)
user_mode = False
# name of the usecase
user_name = test_user
