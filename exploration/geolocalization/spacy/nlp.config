[paths]
train = null
dev = null
vectors = null
init_tok2vec = null

[system]
gpu_allocator = "pytorch"
seed = 0

[nlp]
lang = "fr"
batch_size = 128
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

pipeline = ["tokenizer_component", "normalizer_component",
            "dbpedia"]

[components]

[components.tokenizer_component]
factory = "tokenizer_component"

[components.normalizer_component]
factory = "normalizer_component"

[components.dbpedia]
factory = "DBpedia_spotlight"
overwrite_ents = false
language_code= "fr"
confidence = 0.3
types =  ["DBpedia:Place", "DBpedia:Organisation"]

